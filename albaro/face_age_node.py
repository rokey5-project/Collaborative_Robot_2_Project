import os
import tempfile
import subprocess
import time
import threading
from queue import Queue
from pathlib import Path
from PIL import Image
import torch
from transformers import AutoImageProcessor, SiglipForImageClassification
from dotenv import load_dotenv
from openai import OpenAI
import cv2

import rclpy
from rclpy.node import Node
from std_msgs.msg import Bool, String

# =====================================================
# 1. í™˜ê²½ ì„¤ì • ë° .env ê²½ë¡œ ë³´ì • (ìˆ˜ì •ëœ ë¶€ë¶„)
# =====================================================
# ëŸ°ì¹˜ íŒŒì¼ ì‹¤í–‰ ì‹œ ê²½ë¡œ ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì ˆëŒ€ ê²½ë¡œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
def load_env_file():
    # 1. í˜„ìž¬ íŒŒì¼ì˜ ë¶€ëª¨ í´ë” (albaro/albaro/)
    current_dir = Path(__file__).resolve().parent
    # 2. íŒ¨í‚¤ì§€ ë£¨íŠ¸ í´ë” (albaro/)
    package_root = current_dir.parent

    # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ .env íŒŒì¼ ë¡œë“œ
    env_locations = [current_dir / ".env", package_root / ".env", Path.cwd() / ".env"]
    
    for loc in env_locations:
        if loc.exists():
            load_dotenv(loc, override=True)
            return loc
    return None

env_path = load_env_file()
openai_api_key = os.getenv("OPENAI_API_KEY")

# =====================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ì›ë³¸ ìœ ì§€)
# =====================================================
def iou(boxA, boxB):
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])
    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])
    interW = max(0, xB - xA)
    interH = max(0, yB - yA)
    interArea = interW * interH
    union = boxA[2] * boxA[3] + boxB[2] * boxB[3] - interArea
    return interArea / union if union > 0 else 0.0

# =====================================================
# 2. FaceAgeNode í´ëž˜ìŠ¤
# =====================================================
class FaceAgeNode(Node):
    def __init__(self):
        super().__init__('face_age_node')
        
        # API Key ì²´í¬
        if not openai_api_key:
            self.get_logger().error(f"âŒ API KEY ë¡œë“œ ì‹¤íŒ¨! ì‹œë„í•œ ê²½ë¡œ: {env_path if env_path else 'None'}")
            raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ROS2 ì„¤ì •
        self.sub = self.create_subscription(Bool, '/need_face_check', self.start_callback, 10)
        self.done_pub = self.create_publisher(String, '/task_done', 10)
        
        # ëª¨ë¸ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = OpenAI(api_key=openai_api_key)
        model_name = "prithivMLmods/facial-age-detection"
        self.model = SiglipForImageClassification.from_pretrained(model_name)
        self.processor = AutoImageProcessor.from_pretrained(model_name, use_fast=True)
        self.id2label = {
            0: "age 01-10", 1: "age 11-20", 2: "age 21-30", 3: "age 31-40",
            4: "age 41-55", 5: "age 56-65", 6: "age 66-80", 7: "age 80+"
        }
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

        # ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜
        self.next_person_id = 0
        self.tracks = {}
        self.TRACK_IOU_TH = 0.4
        self.TRACK_TTL = 2.0
        self.is_active = False

        # TTS í ë° ìŠ¤ë ˆë“œ
        self.tts_queue = Queue()
        self.tts_thread = threading.Thread(target=self.tts_worker, daemon=True)
        self.tts_thread.start()

        self.get_logger().info("--- FaceAgeNode Online: Waiting for Signal ---")

    def start_callback(self, msg: Bool):
        if msg.data and not self.is_active:
            self.get_logger().info("ðŸ”ž ì„±ì¸ ì¸ì¦ í”„ë¡œì„¸ìŠ¤ ì‹œìž‘")
            self.is_active = True
            threading.Thread(target=self.run_logic, daemon=True).start()

    def _ensure_resources_cleaned(self):
        cv2.destroyAllWindows()
        for _ in range(5): cv2.waitKey(1)
        temp_cap = cv2.VideoCapture(8)
        if temp_cap.isOpened():
            temp_cap.release()
            time.sleep(0.5)

    def tts_worker(self):
        while True:
            text = self.tts_queue.get()
            if text is None: break
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
                    audio_path = f.name
                with self.client.audio.speech.with_streaming_response.create(
                    model="gpt-4o-mini-tts", voice="alloy", input=text
                ) as response:
                    response.stream_to_file(audio_path)
                subprocess.run(["ffplay", "-nodisp", "-autoexit", audio_path],
                               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                os.remove(audio_path)
            except Exception as e:
                self.get_logger().error(f"TTS Error: {e}")
            finally:
                self.tts_queue.task_done()

    def classify_image(self, image):
        image = Image.fromarray(image).convert("RGB")
        inputs = self.processor(images=image, return_tensors="pt")
        with torch.no_grad():
            outputs = self.model(**inputs)
            probs = torch.softmax(outputs.logits, dim=1).squeeze()
        return self.id2label[int(torch.argmax(probs))]

    def assign_id(self, box):
        now = time.time()
        best_iou, best_id = 0.0, None
        for pid, info in self.tracks.items():
            score = iou(box, info["box"])
            if score > best_iou:
                best_iou, best_id = score, pid
        if best_iou >= self.TRACK_IOU_TH:
            self.tracks[best_id]["box"] = box
            self.tracks[best_id]["last_seen"] = now
            return best_id
        pid = self.next_person_id
        self.next_person_id += 1
        self.tracks[pid] = {"box": box, "warned": False, "last_seen": now}
        return pid

    def cleanup_tracks(self):
        now = time.time()
        self.tracks = {pid: info for pid, info in self.tracks.items()
                       if now - info["last_seen"] <= self.TRACK_TTL}

    def run_logic(self):
        self._ensure_resources_cleaned()
        cap = cv2.VideoCapture(8)
        
        if not cap.isOpened():
            self.get_logger().error("ì›¹ìº  8ë²ˆ ì˜¤í”ˆ ì‹¤íŒ¨!")
            self.is_active = False
            return

        start_time = time.time()
        # 15ì´ˆ ë™ì•ˆ ê°ì§€ ìˆ˜í–‰
        while rclpy.ok() and (time.time() - start_time < 15.0):
            ret, frame = cap.read()
            if not ret: break

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, 1.1, 10, minSize=(30, 30))

            for (x, y, w, h) in faces:
                pid = self.assign_id((x, y, w, h))
                face = frame[y:y+h, x:x+w]
                if face.size == 0: continue
                
                age_group = self.classify_image(face)

                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                cv2.putText(frame, f"ID {pid} | {age_group}", (x, y-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                if age_group in ("age 01-10", "age 11-20"):
                    if not self.tracks[pid]["warned"]:
                        self.tts_queue.put("ë¯¸ì„±ë…„ìžëŠ” êµ¬ë§¤í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        self.tracks[pid]["warned"] = True

            self.cleanup_tracks()
            cv2.imshow("Age Detection", frame)
            if cv2.waitKey(1) & 0xFF == 27: break

        cap.release()
        cv2.destroyAllWindows()
        
        # ì™„ë£Œ ì‹ í˜¸ ì†¡ì‹ 
        done_msg = String()
        done_msg.data = "CALC_DONE"
        self.done_pub.publish(done_msg)
        
        self.is_active = False
        self.get_logger().info("--- ì„±ì¸ ì¸ì¦ ì¢…ë£Œ ë° ë¦¬ì…‹ ì‹ í˜¸ ì†¡ì‹  ---")

def main():
    rclpy.init()
    try:
        node = FaceAgeNode()
        rclpy.spin(node)
    except Exception as e:
        print(f"Error: {e}")
    finally:
        # ì¤‘ë³µ ì…§ë‹¤ìš´ ì—ëŸ¬ ë°©ì§€
        if rclpy.ok():
            rclpy.shutdown()

if __name__ == "__main__":
    main()