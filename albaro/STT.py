from openai import OpenAI
import sounddevice as sd
import scipy.io.wavfile as wav
import os
from pathlib import Path

class STT:
    def __init__(self, openai_api_key=None):
        self.api_key = os.getenv("OPENAI_API_KEY")
        
        # [ìˆ˜ì •] ì¡°ê±´ë¬¸ ë‹¨ìˆœí™”: í‚¤ê°€ sk-ë¡œ ì‹œì‘í•˜ë©´ ì •ìƒìœ¼ë¡œ íŒë‹¨
        if self.api_key and self.api_key.strip().startswith("sk-"):
            try:
                self.client = OpenAI(api_key=self.api_key)
                # ì´ˆê¸°í™” ì„±ê³µ ë¡œê·¸ (ê¸¸ì´ë§Œ ì‚´ì§ ë…¸ì¶œ)
                print(f"âœ… [STT] OpenAI í´ë¼ì´ì–¸íŠ¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.client = None
        else:
            print("âš ï¸ [STT ê²½ê³ ] ìœ íš¨í•œ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            self.client = None

        self.duration = 5       
        self.samplerate = 16000 

    def speech2text(self):
        if not self.client:
            print("âŒ [STT] API í‚¤ê°€ ì—†ì–´ ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", flush=True)
            return None, None

        print("ğŸ”´ [STT] ìŒì„± ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤. (5ì´ˆ ë™ì•ˆ ë§ì”€í•´ì£¼ì„¸ìš”)", flush=True)
        try:
            # 1. ë…¹ìŒ ìˆ˜í–‰
            audio = sd.rec(
                int(self.duration * self.samplerate),
                samplerate=self.samplerate,
                channels=1,
                dtype="int16",
            )
            sd.wait()
            print("ğŸŸ¢ [STT] ë…¹ìŒ ì™„ë£Œ. Whisper ë¶„ì„ ì¤‘...", flush=True)

            # 2. íŒŒì¼ ì €ì¥ (ì¸ì½”ë”© ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ë‹¨ìˆœ ê²½ë¡œ ì‚¬ìš©)
            # tempfile ëŒ€ì‹  ì‚¬ìš©ì í™ˆ ë””ë ‰í† ë¦¬ë‚˜ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì— ê³ ì •ëœ ì´ë¦„ìœ¼ë¡œ ì €ì¥
            wav_path = os.path.join(os.path.expanduser("~"), "temp_stt_audio.wav")
            wav.write(wav_path, self.samplerate, audio)

            # 3. Whisper API í˜¸ì¶œ
            with open(wav_path, "rb") as f:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f
                )
            
            text = transcript.text.strip()
            print(f"âœ… [STT ê²°ê³¼]: {text}", flush=True)
            return text, wav_path

        except Exception as e:
            # [ìˆ˜ì •] ascii ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ strë¡œ ëª…ì‹œì  ë³€í™˜
            error_msg = str(e)
            print(f"âŒ [STT ì—ëŸ¬ ë°œìƒ]: {error_msg}", flush=True)
            return None, None

# ==========================================
# ë‹¨ë… ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (python3 STT.py)
# ==========================================
if __name__ == "__main__":
    stt = STT()
    text, path = stt.speech2text()
    
    if text:
        print(f"\nìµœì¢… ì¸ì‹ ë¬¸ìì—´: {text}")
    
    # ìƒì„±ëœ íŒŒì¼ ì‚­ì œ (í•„ìš”ì‹œ)
    if path and os.path.exists(path):
        try:
            os.remove(path)
        except:
            pass